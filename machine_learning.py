# -*- coding: utf-8 -*-
"""Machine_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19nNJ4Ga2daK6K2r4at9ViHN-kIjbPsgK

### Part 1: Machine Learning Method

Details of method
"""

#  lots of Python code here

import pandas as pd
import re
from nltk.corpus import stopwords
from nltk import word_tokenize    
from nltk.tokenize import wordpunct_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB
from sklearn.svm import LinearSVC, SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score                  #from sklearn import cross_validation
import pandas as pd
import numpy as np
import spacy 
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS = set(stopwords.words('english'))
from spacy.lang.en.stop_words import STOP_WORDS
from sklearn import model_selection, svm

import en_core_web_sm
import spacy
!pip install -U spacy download en_core_web_sm
!pip install -U spacy download en_core_web_sm



sp = spacy.load('en_core_web_sm')
df = pd.read_csv('axcs_train.csv')
df_test = pd.read_csv('axcs_test.csv')                    # load spacy for processing datasets
print(len(df))
print(len(df_test))

def getcleaned(dtf):
    d=dtf.loc[:,'Abstract']
    cleaned_data = []                              # emove puntuation , conver to lower case in this function and cleaned data is obtained
    for i in range(len(dtf)):
        d[i] = re.sub(r'[^\w\s]','',str(d[i]))
        d[i] = d[i].lower()
        cleaned_data.append(d[i])
    return cleaned_data

cleaned_train = getcleaned(df)
cleaned_train

cleaned_test = getcleaned(df_test)
cleaned_test

len(cleaned_train)
len(cleaned_test)

def meaningful_words(cleaned_data,df):
    for i in range(len(cleaned_data)):
        useful_words = []                             # useful words are usually in the noun form and using lemmatization we extract oly nouns to form vocab list
        sentence = sp(cleaned_data[i])
        for word in sentence:
            if str(word) not in STOP_WORDS and word.pos_ == "NOUN":
                print(word, word.pos_)
                useful_words.append(word.lemma_)
        df.loc[i,"meaningful_words"] = str(useful_words)    
    return df

dataframe = meaningful_words(cleaned_train,df)

dataframe_test = meaningful_words(cleaned_test,df_test)

def modify_dataframe(df):
    df_mod = df[['InfoTheory',"CompVis",'Math','meaningful_words']]          # define a fcuntion to consider only required variables
    return df_mod

df_X_train = modify_dataframe(dataframe)                 
df_X_test = modify_dataframe(dataframe_test)
df_X_train = df_X_train.dropna()              # drop NA if any
df_X_test = df_X_test.dropna()

Train_X = df_X_train['meaningful_words']
Test_X = df_X_test['meaningful_words']                        # vectorize with tfid functions
Tfidf_vect = TfidfVectorizer(max_features=5000)
Tfidf_vect.fit(Train_X)
Tfidf_vect.fit(Test_X)

Train_X_Tfidf = Tfidf_vect.transform(Train_X)           # transformation of values
Test_X_Tfidf = Tfidf_vect.transform(Test_X)

print(Tfidf_vect.vocabulary_)

Train_Y = df_X_train['InfoTheory']                              
Test_Y = df_X_test['InfoTheory']                      # fit model for class infotheory

# fit the training dataset on the classifier
SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')
SVM.fit(Train_X_Tfidf,Train_Y)
# predict the labels on validation dataset
predictions_SVM = SVM.predict(Test_X_Tfidf)
# Use accuracy_score function to get the accuracy
print("SVM Accuracy Score -> ",accuracy_score(predictions_SVM, Test_Y)*100)

print(confusion_matrix(Test_Y,predictions_SVM))
                                                       # get confusion matrix

Train_Y = df_X_train['CompVis']
Test_Y = df_X_test['CompVis']
# fit the training dataset on the classifier
SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')
SVM.fit(Train_X_Tfidf,Train_Y)
# predict the labels on validation dataset
predictions_SVM = SVM.predict(Test_X_Tfidf)                     # fit model for class compvis
# Use accuracy_score function to get the accuracy
print("SVM Accuracy Score -> ",accuracy_score(predictions_SVM, Test_Y)*100)

print(confusion_matrix(Test_Y,predictions_SVM))

Train_Y = df_X_train['Math']
Test_Y = df_X_test['Math']
# fit the training dataset on the classifier
SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')        ## fit model for class Math
SVM.fit(Train_X_Tfidf,Train_Y)
# predict the labels on validation dataset
predictions_SVM = SVM.predict(Test_X_Tfidf)
# Use accuracy_score function to get the accuracy
print("SVM Accuracy Score -> ",accuracy_score(predictions_SVM, Test_Y)*100)

print(confusion_matrix(Test_Y,predictions_SVM))

"""#### Results of Method
Full confusion matrix for method on InfoTheory:

|              | Pred=True | Pred=False |
| -----------  | ----------- | ----------- |
| **Actual=True**  |   15789    |   273  |
| **Actual=False** | 768        |  2848 |

Full confusion matrix for method on CompVis:

|              | Pred=True | Pred=False |
| -----------  | ----------- | ----------- |
| **Actual=True**  | 17442      |   84  |
| **Actual=False** | 614       |   1538 |

Full confusion matrix for method on Math:

|              | Pred=True | Pred=False |
| -----------  | ----------- | ----------- |
| **Actual=True**  | 12813       |   935  |
| **Actual=False** | 1753        |   4177 |


"""

